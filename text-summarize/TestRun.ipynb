{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Embedding, Dense, LSTM, Input, Reshape\n",
    "from keras import optimizers\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import keras\n",
    "import numpy as np\n",
    "from data import Vocab\n",
    "from batcher import Batcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from hps import hps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "embedding_init = keras.initializers.TruncatedNormal(mean=0.0, stddev=0.05, seed=None)\n",
    "embedding_layer = Embedding(hps['vocab_size'], hps['hidden_dim'], embeddings_initializer=embedding_init)\n",
    "\n",
    "encoder_inputs = Input(shape=(None,), name='encoder_inputs')\n",
    "encoder_lstm = LSTM(hps['hidden_dim'], return_state=True, name='encoder_lstm')\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(embedding_layer(encoder_inputs))\n",
    "encoder_states = [state_h, state_c]\n",
    "decoder_inputs = Input(shape=(None,), name='decoder_inputs')\n",
    "decoder_lstm = LSTM(hps['hidden_dim'], return_state=True, return_sequences=True, name='decoder_lstm')\n",
    "decoder_outputs, _, _ = decoder_lstm(embedding_layer(decoder_inputs), initial_state=encoder_states)\n",
    "decoder_dense = Dense(hps['vocab_size'], activation='softmax', name='decoder_dense')\n",
    "dense_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "model = Model([encoder_inputs, decoder_inputs], dense_outputs)\n",
    "adam = optimizers.Adam()\n",
    "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "decoder_state_inputs = [Input(shape=(hps['hidden_dim'],)), Input(shape=(hps['hidden_dim'],))]\n",
    "decoder_outputs, decoder_states = decoder_lstm(decoder_inputs, initial_state=decoder_state_inputs)\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = Model([decoder_inputs] + decoder_state_inputs, [decoder_outputs] + decoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: incorrectly formatted line in vocabulary file: 0800 555 111 356\n",
      "\n",
      "\n",
      "Warning: incorrectly formatted line in vocabulary file: 1800 333 000 139\n",
      "\n",
      "\n",
      "Warning: incorrectly formatted line in vocabulary file: 2 1/2 124\n",
      "\n",
      "\n",
      "Warning: incorrectly formatted line in vocabulary file: 3 1/2 86\n",
      "\n",
      "\n",
      "max_size of vocab was specified as 50000; we now have 50000 words. Stopping reading.\n",
      "Finished constructing vocabulary of 50000 total words. Last word added: perisic\n"
     ]
    }
   ],
   "source": [
    "vocab = Vocab(hps['vocab_path'], hps['vocab_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "  def make_feed_dict(batch, just_enc=False):\n",
    "    \"\"\"Make a feed dictionary mapping parts of the batch to the appropriate placeholders.\n",
    "    Args:\n",
    "      batch: Batch object\n",
    "      just_enc: Boolean. If True, only feed the parts needed for the encoder.\n",
    "    \"\"\"\n",
    "    feed_dict = {}\n",
    "    feed_dict['enc_batch'] = batch.enc_batch\n",
    "    feed_dict['dec_batch'] = batch.dec_batch\n",
    "    feed_dict['target_batch'] = np.eye(hps['vocab_size'])[batch.target_batch]\n",
    "    return feed_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mode = 'test'\n",
    "train_batcher = Batcher(hps['data_path'] + '/{}.bin'.format(mode), vocab, hps, single_pass=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch = train_batcher.next_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feed_dict = make_feed_dict(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, Y = [feed_dict['enc_batch'], feed_dict['dec_batch']], feed_dict['target_batch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 100)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_batch(mode): #mode: train/test/val\n",
    "    hps['mode'] = mode\n",
    "    batcher = Batcher(hps['data_path'] + '/{}.bin'.format(mode), vocab, hps, single_pass=True)\n",
    "#     batcher.fill_example_queue()\n",
    "#     batcher.fill_batch_queue()\n",
    "    while True:\n",
    "        batch = batcher.next_batch()\n",
    "        feed_dict = make_feed_dict(batch)\n",
    "        yield [feed_dict['enc_batch'], feed_dict['dec_batch']], feed_dict['target_batch']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/HelenWang/anaconda/envs/py36/lib/python3.6/site-packages/keras/engine/training_generator.py:44: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\n",
      "  UserWarning('Using a generator with `use_multiprocessing=True`'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Bucket input queue is empty when calling next_batch. Bucket queue size: 0, Input queue size: 0\n",
      "WARNING:tensorflow:Bucket input queue is empty when calling next_batch. Bucket queue size: 0, Input queue size: 0\n",
      "WARNING:tensorflow:Bucket input queue is empty when calling next_batch. Bucket queue size: 0, Input queue size: 0\n",
      "WARNING:tensorflow:Bucket input queue is empty when calling next_batch. Bucket queue size: 0, Input queue size: 0\n",
      "WARNING:tensorflow:Bucket input queue is empty when calling next_batch. Bucket queue size: 0, Input queue size: 0\n",
      "WARNING:tensorflow:Bucket input queue is empty when calling next_batch. Bucket queue size: 0, Input queue size: 0\n",
      "Epoch 1/10\n",
      "15/16 [===========================>..] - ETA: 2:11 - loss: 9.1160 - acc: 0.8623"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/HelenWang/anaconda/envs/py36/lib/python3.6/site-packages/keras/engine/training_generator.py:272: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\n",
      "  UserWarning('Using a generator with `use_multiprocessing=True`'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Bucket input queue is empty when calling next_batch. Bucket queue size: 0, Input queue size: 0\n",
      "WARNING:tensorflow:Bucket input queue is empty when calling next_batch. Bucket queue size: 0, Input queue size: 0\n",
      "WARNING:tensorflow:Bucket input queue is empty when calling next_batch. Bucket queue size: 0, Input queue size: 0\n",
      "WARNING:tensorflow:Bucket input queue is empty when calling next_batch. Bucket queue size: 0, Input queue size: 0\n",
      "WARNING:tensorflow:Bucket input queue is empty when calling next_batch. Bucket queue size: 0, Input queue size: 0\n",
      "WARNING:tensorflow:Bucket input queue is empty when calling next_batch. Bucket queue size: 0, Input queue size: 0\n",
      "16/16 [==============================] - 4750s 297s/step - loss: 8.9724 - acc: 0.8637 - val_loss: 6.4070 - val_acc: 0.8977\n",
      "Epoch 2/10\n",
      " 2/16 [==>...........................] - ETA: 21:44 - loss: 6.1930 - acc: 0.9062"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(generator=generate_batch('test'), steps_per_epoch=hps['batch_size'],\n",
    "                                   epochs=epochs,\n",
    "                                   verbose=1, validation_data=generate_batch('val'), validation_steps=hps['batch_size'],\n",
    "                                  use_multiprocessing=True,workers=6\n",
    "                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "16/16 [==============================] - 29s 2s/step - loss: 10.8203 - acc: 0.0000e+00\n",
      "Epoch 2/10\n",
      "16/16 [==============================] - 19s 1s/step - loss: 10.8122 - acc: 0.4050\n",
      "Epoch 3/10\n",
      "16/16 [==============================] - 16s 1s/step - loss: 10.8036 - acc: 0.9500\n",
      "Epoch 4/10\n",
      "16/16 [==============================] - 19s 1s/step - loss: 10.7947 - acc: 0.9500\n",
      "Epoch 5/10\n",
      "16/16 [==============================] - 18s 1s/step - loss: 10.7838 - acc: 0.9500\n",
      "Epoch 6/10\n",
      "16/16 [==============================] - 17s 1s/step - loss: 10.7690 - acc: 0.9500\n",
      "Epoch 7/10\n",
      "16/16 [==============================] - 16s 973ms/step - loss: 10.7493 - acc: 0.9400\n",
      "Epoch 8/10\n",
      "16/16 [==============================] - 16s 987ms/step - loss: 10.7219 - acc: 0.9306\n",
      "Epoch 9/10\n",
      "16/16 [==============================] - 15s 911ms/step - loss: 10.6823 - acc: 0.9200\n",
      "Epoch 10/10\n",
      "16/16 [==============================] - 14s 894ms/step - loss: 10.6230 - acc: 0.9013\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x5d7fb00b8>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, Y, batch_size=hps['batch_size'], epochs=10,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py36]",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
